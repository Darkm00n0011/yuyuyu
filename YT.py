from scipy.io.wavfile import write
from pydub import AudioSegment, effects
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
import torch
from bark import generate_audio
import sys
import moviepy
print("Python path:", sys.path)
print("MoviePy version:", moviepy.__version__)
import os
import requests
import json
import pytz
from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage
import collections
import openai
import subprocess
import cv2
import numpy as np
from datetime import datetime, time
from pytrends.request import TrendReq
from pydub.effects import normalize
from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip
from moviepy.video.fx import fadein, fadeout
from PIL import Image, ImageDraw, ImageFont

SHORTS_DURATION=59
LONG_VIDEO_DURATION=600
VIDEO_QUALITY="4K"
SHORTS_UPLOAD_TIME_UTC = time(15, 0)  # Ø³Ø§Ø¹Øª Û³ Ø¨Ø¹Ø¯Ø§Ø²Ø¸Ù‡Ø± UTC
LONG_VIDEO_UPLOAD_TIME_UTC= time(12, 0)  # Ø³Ø§Ø¹Øª Û±Û² Ø¸Ù‡Ø± UTC


# Load environment variables from Railway
CLIENT_ID = os.getenv("CLIENT_ID")
CLIENT_SECRET = os.getenv("CLIENT_SECRET")
REFRESH_TOKEN = os.getenv("REFRESH_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
VOICE_ID = "EXAVITQu4vr4xnSDxMaL"  # Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø¢ÛŒâ€ŒØ¯ÛŒ ØµØ¯Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡â€ŒØ§Øª Ø±Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒ

# YouTube API URLs
TOKEN_URL = "https://oauth2.googleapis.com/token"
METADATA_URL = "https://www.googleapis.com/youtube/v3/videos"
UPLOAD_URL = "https://www.googleapis.com/upload/youtube/v3/videos"

# ØªÙ†Ø¸ÛŒÙ… Ù…Ù†Ø·Ù‚Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ø¨Ù‡ Eastern Time (ET)
EST = pytz.timezone('America/New_York')

# ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ® Ø¢Ø®Ø±ÛŒÙ† Ø¢Ù¾Ù„ÙˆØ¯
UPLOAD_LOG_FILE = "upload_log.json"

# Ù…Ø³ÛŒØ± ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ (Ù†Ø§Ù… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†)
LONG_VIDEO_FILE = "long_video.mp4"  # ÙˆÛŒØ¯ÛŒÙˆÛŒ 5 ØªØ§ 10 Ø¯Ù‚ÛŒÙ‚Ù‡â€ŒØ§ÛŒ
SHORT_VIDEO_FILE = "short_video.mp4"  # ÙˆÛŒØ¯ÛŒÙˆÛŒ Shorts

# ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù¾Ù„ÙˆØ¯Ù‡Ø§ Ø¯Ø± Ø±ÙˆØ²
MAX_LONG_UPLOADS = 1  # ÙÙ‚Ø· 1 ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø¨Ù„Ù†Ø¯ Ø¯Ø± Ø±ÙˆØ²
MAX_SHORTS_UPLOADS = 1  # ÙÙ‚Ø· 1 Shorts Ø¯Ø± Ø±ÙˆØ²

def load_trending_topics():
    file_path = "trending_topics.json"
    if not os.path.exists(file_path) or os.stat(file_path).st_size == 0:
        # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø§Ú¯Ø± ÙØ§ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª
        default_data = [
            {"title": "Minecraft Secrets", "popularity": 95},
            {"title": "AI in 2025", "popularity": 90}
        ]
        with open(file_path, "w") as file:
            json.dump(default_data, file, indent=4)
        return default_data  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†

    try:
        with open(file_path, "r") as file:
            return json.load(file)
    except json.JSONDecodeError:
        print("âŒ Error: JSON file is corrupted. Resetting it.")
        return load_trending_topics()  # ÙØ§ÛŒÙ„ Ø±Ø§ Ø±ÛŒØ³Øª Ú©Ù†

def fetch_youtube_trending(region_code="US", max_results=10):

    url = "https://www.googleapis.com/youtube/v3/videos"
    params = {
        "part": "snippet,statistics",
        "chart": "mostPopular",
        "regionCode": region_code,
        "maxResults": max_results,
        "key": YOUTUBE_API_KEY  # ğŸ”¹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Key
    }

    response = requests.get(url, params=params)
    
    if response.status_code != 200:
        print("âŒ Error fetching trending videos:", response.json())
        return []

    trending_videos = response.json().get("items", [])
    trending_topics = []

    for rank, video in enumerate(trending_videos, start=1):
        try:
            title = video["snippet"]["title"]
            description = video["snippet"]["description"]
            channel = video["snippet"]["channelTitle"]
            video_id = video["id"]
            view_count = int(video["statistics"].get("viewCount", 0))
            like_count = int(video["statistics"].get("likeCount", 0))

            # ğŸ”¹ Ù…Ù‚ÛŒØ§Ø³ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ùˆ Ù„Ø§ÛŒÚ© (Ø¨ÛŒÙ† Û° ØªØ§ Û±Û°Û°)
            popularity = min(100, (view_count // 10000) + (like_count // 500))

            trending_topics.append({
                "rank": rank,  # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø±ØªØ¨Ù‡ ØªØ±Ù†Ø¯
                "title": title,
                "description": description,
                "channel": channel,
                "video_id": video_id,
                "view_count": view_count,
                "like_count": like_count,
                "popularity": popularity
            })

        except KeyError as e:
            print(f"âš ï¸ Missing key {e} for video: {video.get('id', 'Unknown')}")

    if trending_topics:  # âœ… ÙÙ‚Ø· Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
        with open("trending_topics.json", "w") as file:
            json.dump(trending_topics, file, indent=2)

        print(f"âœ… {len(trending_topics)} trending topics saved in trending_topics.json")

    return trending_topics  # ğŸ”¹ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ

def fetch_google_trends(region="united_states"):
    """ Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ² Ø§Ø² Google Trends Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± trending_topics.json """

    pytrends = TrendReq(hl='en-US', tz=360)
    
    # ğŸ”¹ Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ø´ÙˆØ± Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ÛŒØ§ Ù†Ù‡
    try:
        trending_searches = pytrends.trending_searches(pn=region)
    except Exception as e:
        print(f"âŒ Error fetching Google Trends for {region}: {e}")
        return []

    if trending_searches is None or trending_searches.empty:
        print("âŒ No Google Trends data found!")
        return []

    trends = trending_searches[0].tolist()[:10]  # ğŸ”¹ ÙÙ‚Ø· Û±Û° ØªØ±Ù†Ø¯ Ø¨Ø±ØªØ±
    
    google_trends = []
    for i, trend in enumerate(trends):
        search_volume = None  # ğŸ”¹ Ù…Ù‚Ø¯Ø§Ø± Ø§ÙˆÙ„ÛŒÙ‡ Ø­Ø¬Ù… Ø¬Ø³ØªØ¬Ùˆ
        try:
            pytrends.build_payload([trend], timeframe="now 1-d", geo=region.upper())
            interest_over_time = pytrends.interest_over_time()
            if not interest_over_time.empty:
                search_volume = int(interest_over_time.iloc[-1, 0])  # ğŸ”¹ Ø¢Ø®Ø±ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡
        except Exception as e:
            print(f"âš ï¸ Could not fetch interest for {trend}: {e}")

        popularity = search_volume if search_volume is not None else (100 - (i * 10))  # ğŸ”¹ Ù…Ù‚Ø¯Ø§Ø± ØªØ®Ù…ÛŒÙ†ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ Ø¯Ø§Ø¯Ù‡

        google_trends.append({
            "title": trend,
            "source": "Google Trends",
            "search_volume": search_volume,
            "popularity": popularity
        })

    if google_trends:  # âœ… Ø°Ø®ÛŒØ±Ù‡ ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø§Ø´ØªÙ† Ø¯Ø§Ø¯Ù‡
        with open("trending_topics.json", "w") as file:
            json.dump(google_trends, file, indent=2)

        print(f"âœ… {len(google_trends)} Google Trends saved in trending_topics.json")

    return google_trends  # ğŸ”¹ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ

def fetch_reddit_trends(subreddits=["gaming"], limit=10, time_period="day"):
    """ Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø·Ø±ÙØ¯Ø§Ø± Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Reddit subreddit Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± trending_topics.json """

    headers = {"User-Agent": "Mozilla/5.0"}
    reddit_trends = []

    for subreddit in subreddits:
        url = f"https://www.reddit.com/r/{subreddit}/top.json?t={time_period}&limit={limit}"

        try:
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()  # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª HTTP
            data = response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ Error fetching Reddit trends for {subreddit}: {e}")
            continue
        except json.JSONDecodeError:
            print(f"âŒ Error decoding JSON response from Reddit ({subreddit})!")
            continue

        posts = data.get("data", {}).get("children", [])
        if not posts:
            print(f"âš  No trending posts found on r/{subreddit}!")
            continue

        for post in posts:
            post_data = post["data"]
            title = post_data.get("title", "Unknown Title")
            post_id = post_data.get("id", "")
            url = f"https://www.reddit.com{post_data.get('permalink', '')}"
            ups = post_data.get("ups", 0)
            score = post_data.get("score", 0)

            # Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø­Ø¨ÙˆØ¨ÛŒØª (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø² Ø¯Ø± Ù…ÛŒØ§Ù† Ù¾Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯Ù‡)
            popularity = min(100, (score / max(1, posts[0]["data"].get("score", 1))) * 100)

            reddit_trends.append({
                "title": title,
                "post_id": post_id,
                "url": url,
                "subreddit": subreddit,
                "source": "Reddit",
                "popularity": round(popularity, 2)  # Ù…Ù‚Ø¯Ø§Ø± Ø±Ø§ ØªØ§ Ø¯Ùˆ Ø±Ù‚Ù… Ø§Ø¹Ø´Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
            })

    if reddit_trends:  # âœ… Ø°Ø®ÛŒØ±Ù‡ ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ø¯Ø§Ø´ØªÙ† Ø¯Ø§Ø¯Ù‡
        with open("trending_topics.json", "w") as file:
            json.dump(reddit_trends, file, indent=2)

        print(f"âœ… {len(reddit_trends)} Reddit trends saved in trending_topics.json")

    return reddit_trends  # ğŸ”¹ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¯Ø± Ø¨Ø±Ù†Ø§Ù…Ù‡

def fetch_all_trends(region_code="US", reddit_subreddits=["gaming"], reddit_limit=10, time_period="day"):
    """ Ø¯Ø±ÛŒØ§ÙØª Ùˆ ØªØ±Ú©ÛŒØ¨ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ù†Ø¯ Ø§Ø² ÛŒÙˆØªÛŒÙˆØ¨ØŒ Ú¯ÙˆÚ¯Ù„ ØªØ±Ù†Ø¯Ø²ØŒ Ùˆ Ø±Ø¯ÛŒØª Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± trending_topics.json """

    print("ğŸ” Fetching YouTube Trends...")
    youtube_trends = fetch_youtube_trending(region_code)

    print("ğŸ” Fetching Google Trends...")
    google_trends = fetch_google_trends()

    print("ğŸ” Fetching Reddit Trends...")
    reddit_trends = fetch_reddit_trends(reddit_subreddits, reddit_limit, time_period)

    # ØªØ±Ú©ÛŒØ¨ ØªÙ…Ø§Ù… ØªØ±Ù†Ø¯Ù‡Ø§ Ø¯Ø± ÛŒÚ© Ù„ÛŒØ³Øª ÙˆØ§Ø­Ø¯
    all_trends = youtube_trends + google_trends + reddit_trends

    # Ø§ÙØ²ÙˆØ¯Ù† Ø²Ù…Ø§Ù† Ø¢Ø®Ø±ÛŒÙ† Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
    all_trends_data = {
        "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "trends": all_trends
    }

    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
    with open("trending_topics.json", "w") as file:
        json.dump(all_trends_data, file, indent=2)

    print(f"âœ… {len(all_trends)} trends saved in trending_topics.json")

    return all_trends


def select_best_trending_topic(json_file="trending_topics.json"):

    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ù†Ø¯
    try:
        with open(json_file, "r", encoding="utf-8") as file:
            trends = json.load(file)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        print(f"âŒ Error: {json_file} not found or contains invalid JSON. ({e})")
        return None

    # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯Ù† Ù„ÛŒØ³Øª ØªØ±Ù†Ø¯Ù‡Ø§
    if not trends:
        print("âŒ No trending topics found.")
        return None

    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø± (Ø¨Ø§ÛŒØ¯ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§Ø´Ù†Ø¯ Ùˆ Ú©Ù„ÛŒØ¯ 'topic' Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯)
    valid_trends = [t for t in trends if isinstance(t, dict) and "topic" in t]

    if not valid_trends:
        print("âŒ No valid trending topics found.")
        return None

    # Ø´Ù…Ø§Ø±Ø´ ØªØ¹Ø¯Ø§Ø¯ ØªÚ©Ø±Ø§Ø± Ù‡Ø± Ù…ÙˆØ¶ÙˆØ¹
    topic_count = collections.Counter([t["topic"] for t in valid_trends])

    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¨ÛŒØ´ØªØ±ÛŒÙ† ØªÚ©Ø±Ø§Ø±
    sorted_topics = sorted(topic_count.items(), key=lambda x: x[1], reverse=True)

    # ØªØ¹Ø±ÛŒÙ Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ø±ØªØ¨Ø·
    keywords = ["minecraft", "knowledge", "gaming", "ai", "technology", "computers"]

    # Ø§Ù†ØªØ®Ø§Ø¨ Ø§ÙˆÙ„ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ ÛŒÚ©ÛŒ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ
    for topic, count in sorted_topics:
        if any(keyword in topic.lower() for keyword in keywords):
            print(f"âœ… Best topic selected: {topic} (Found in {count} sources)")
            return topic

    # Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯Ù† Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø±ØªØ¨Ø·ØŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…ÙˆØ¶ÙˆØ¹ Ù¾Ø±ØªØ±Ù†Ø¯ØªØ±
    best_fallback_topic = sorted_topics[0][0] if sorted_topics else None
    if best_fallback_topic:
        print(f"âš  No suitable trending topic found. Using top topic: {best_fallback_topic}")
    
    return best_fallback_topic

# Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹
topic = select_best_trending_topic()
import requests

import requests
import os

PIXABAY_API_KEY = "YOUR_PIXABAY_API_KEY"  # Ú©Ù„ÛŒØ¯ API Ø±Ùˆ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†
PIXABAY_URL = "https://pixabay.com/api/videos/"

def download_best_minecraft_background(output_video="background.mp4"):
    params = {
        "key": PIXABAY_API_KEY,
        "q": "Minecraft gameplay",
        "video_type": "film",
        "per_page": 5  # Ø¯Ø±ÛŒØ§ÙØª 5 ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø±ØªØ±
    }

    response = requests.get(PIXABAY_URL, params=params)
    if response.status_code == 200:
        data = response.json()
        if not data["hits"]:
            print("âŒ No Minecraft videos found on Pixabay.")
            return None

        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©ÛŒÙÛŒØª (Ø±Ø²ÙˆÙ„ÙˆØ´Ù† Ø¹Ø±Ø¶ÛŒ) Ùˆ Ø·ÙˆÙ„ ÙˆÛŒØ¯ÛŒÙˆ
        sorted_videos = sorted(
            data["hits"], 
            key=lambda vid: (vid["videos"]["medium"]["width"], vid["duration"]), 
            reverse=True  # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ú©ÛŒÙÛŒØª ÙˆÛŒØ¯ÛŒÙˆ
        )

        best_video = sorted_videos[0]["videos"]["medium"]["url"]  # Ø¨Ù‡ØªØ±ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ

        print(f"âœ… Selected best video: {best_video}")

        # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ
        video_response = requests.get(best_video, stream=True)
        if video_response.status_code == 200:
            with open(output_video, "wb") as f:
                for chunk in video_response.iter_content(chunk_size=1024):
                    f.write(chunk)
            print(f"âœ… Downloaded best background video: {output_video}")
            return output_video
        else:
            print("âŒ Error downloading video.")
    else:
        print("âŒ Error fetching videos from Pixabay.")
    
    return None

# ØªØ³Øª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¨Ù‡ØªØ±ÛŒÙ† ÙˆÛŒØ¯ÛŒÙˆ
download_best_minecraft_background()


def generate_video_script(topic):
    if not topic:
        print("âŒ Error: No topic provided!")
        return None

    prompt = f"""
    Write a viral YouTube video script for the topic: {topic}. 
    The script should be informal, fun, and engaging like a famous YouTuber. 
    The tone should be energetic and natural, avoiding anything too formal or robotic.

    Structure:
    1ï¸âƒ£ Hook (First 5-10 seconds) - Start with a shocking fact, an exciting question, or a crazy statement.
    2ï¸âƒ£ Main Content (70% of the video) - Explain the topic in a super fun and easy way, like talking to a friend.
    3ï¸âƒ£ Call to Action (Last 10 seconds) - Encourage viewers to like, comment, and subscribe in a way that feels natural.

    Now, generate a script with this same fun, engaging style for the topic: {topic}.
    """

    API_KEY = os.getenv("MISTRAL_API_KEY")  # Fetch API key from Railway environment
    if not API_KEY:
        print("âŒ Error: MISTRAL_API_KEY is missing!")
        return None

    client = MistralClient(api_key=API_KEY)  # Initialize the Mistral API client

    try:
        response = client.chat(
            model="mistral-large-latest",
            messages=[ChatMessage(role="user", content=prompt)],
            max_tokens=500,
            temperature=0.8
        )

        script = response.choices[0].message.content.strip()

        if not script:
            print("âŒ Error: No script received from API")
            return None

        return script

    except Exception as e:
        print("âŒ API Request Error:", str(e))
        return None


# âœ… **Test the Function**
if __name__ == "__main__":
    topic = "Minecraft Tricks"  # Example topic
    script = generate_video_script(topic)

    if script:
        print("ğŸ¬ Generated Script:\n", script)
    else:
        print("âŒ Error: Script generation failed!")
        sys.exit(1)  # Exit if script generation fails

def generate_video_metadata(topic):
    
    #ØªÙˆÙ„ÛŒØ¯ Ø¹Ù†ÙˆØ§Ù†ØŒ ØªÙˆØ¶ÛŒØ­Ø§Øª Ùˆ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒÙˆØªÛŒÙˆØ¨.
    
    print("ğŸ“ Generating video metadata...")

    prompt = f"""
    Generate an engaging YouTube video title, description, and relevant hashtags for a video about "{topic}".
    
    - The title should be eye-catching and optimized for high CTR.
    - The description should include a short summary of the video, a call to action, and links.
    - The hashtags should be relevant and increase discoverability.
    
    Return the output in **valid JSON format** with keys: "title", "description", and "hashtags".
    """

    try:
        client = openai.Client()  # Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ ØµØ­ÛŒØ­ Ú©Ù„Ø§ÛŒÙ†Øª OpenAI
        response = client.chat.completions.create(
         model="gpt-3.5-turbo",  # ÛŒØ§ "o3-mini"
         messages=[{"role": "user", "content": prompt}],
         max_tokens=250
)

        content = response.choices[0].message.content.strip()

        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ JSON
        try:
            metadata = json.loads(content)
            if not all(key in metadata for key in ["title", "description", "hashtags"]):
                raise ValueError("Missing expected keys in JSON")
        except (json.JSONDecodeError, ValueError):
            print("âš  Warning: Invalid JSON received from OpenAI. Using default metadata.")
            metadata = {
                "title": f"Awesome Video About {topic}!",
                "description": f"This video is all about {topic}. Stay tuned for more!",
                "hashtags": "#YouTube #Trending"
            }

        print("âœ… Video metadata generated successfully!")
        return metadata
    except Exception as e:
        print("âŒ Error generating metadata:", str(e))
        return None

metadata = generate_video_metadata(topic)
print(metadata)


def generate_voiceover(script, output_audio="voiceover.wav"):
    try:
        audio_array = generate_audio(script)  # Bark-based voice generation
        sample_rate = 24000
        write(output_audio, sample_rate, np.array(audio_array * 32767, dtype=np.int16))
        return output_audio
    except Exception as e:
        print(f"âŒ Error generating voiceover: {str(e)}")
        return None

def generate_video(voiceover, background_video, output_video="final_video.mp4"):
    try:
        command = f"ffmpeg -i {background_video} -i {voiceover} -c:v copy -c:a aac {output_video}"
        subprocess.run(command, shell=True, check=True)
        return output_video
    except Exception as e:
        print("âŒ Error generating video:", str(e))
        return None


def generate_subtitles(audio_file, output_srt="subtitles.srt"):
    
    #ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³ Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø¨Ø§ ØµØ¯Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Whisper AI
    
    try:
        response = openai.Audio.transcribe("whisper-1", audio_file)
        subtitles = response["text"]

        with open(output_srt, "w") as srt_file:
            srt_file.write(subtitles)

        print("âœ… Subtitles generated successfully!")
        return output_srt
    except Exception as e:
        print("âŒ Error generating subtitles:", str(e))
        return None


def enhance_audio(input_audio, output_audio="enhanced_voiceover.mp3"):
    try:
        audio = AudioSegment.from_file(input_audio)
        enhanced_audio = effects.normalize(audio)
        enhanced_audio.export(output_audio, format="mp3")
        return output_audio
    except Exception as e:
        print(f"âŒ Error enhancing audio: {e}")
        return None

def enhance_video(input_video, output_video="enhanced_video.mp4"):
    try:
        clip = VideoFileClip(input_video)
        title_text = TextClip("ğŸ”¥ Minecraft Fact!", fontsize=70, color="white").set_position("center").set_duration(3)
        final_clip = CompositeVideoClip([clip, title_text])
        final_clip.write_videofile(output_video, codec="libx264", fps=30)
        return output_video
    except Exception as e:
        print(f"âŒ Error enhancing video: {e}")
        return None

def add_video_effects(input_video, output_video="final_video_with_effects.mp4"):
    
    #Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÙÚ©Øªâ€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ±ÛŒØŒ ØªØ±Ù†Ø²ÛŒØ´Ù†â€ŒÙ‡Ø§ Ùˆ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¨Ù‡ ÙˆÛŒØ¯ÛŒÙˆ
    
    print("ğŸ¬ Adding effects to video...")

    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ø§ØµÙ„ÛŒ
    clip = VideoFileClip(input_video)

    # Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ù…ØªØ­Ø±Ú©
    txt_clip = TextClip("ğŸ”¥ Amazing Minecraft Fact!", fontsize=80, color='yellow', font="Impact-Bold")
    txt_clip = txt_clip.set_position(("center", "top")).set_duration(3)  # Ù†Ù…Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ Û³ Ø«Ø§Ù†ÛŒÙ‡

    # ØªØ±Ú©ÛŒØ¨ ÙˆÛŒØ¯ÛŒÙˆ Ùˆ Ù…ØªÙ†
    final = CompositeVideoClip([clip, txt_clip])

    # Ø°Ø®ÛŒØ±Ù‡ ÙˆÛŒØ¯ÛŒÙˆ
    final.write_videofile(output_video, codec="libx264", fps=30)
    print(f"âœ… Video with effects saved as {output_video}")
    return output_video

def generate_thumbnail(topic, output_file="thumbnail.png"):
    
    #ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø¬Ø°Ø§Ø¨ Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆØŒ Ø§Ø¨ØªØ¯Ø§ Ø¨Ø§ DALLÂ·EØŒ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ØŒ Ø¨Ø§ ÛŒÚ© ØªØµÙˆÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶.
    
    print("ğŸ–¼ Generating thumbnail...")

    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ØªÙˆÙ„ÛŒØ¯ ØªØµÙˆÛŒØ± Ø¨Ø§ DALLÂ·E
    try:
        response = openai.Image.create(
            model="dall-e-3",
            prompt=f"Create a high-quality YouTube thumbnail for a video about {topic}. It should be colorful, eye-catching, and engaging.",
            n=1,
            size="1024x1024"
        )

        if "data" in response and response["data"]:
            image_url = response["data"][0]["url"]
            if image_url:
                img = Image.open(requests.get(image_url, stream=True).raw)
                print("âœ… Thumbnail generated using DALLÂ·E!")
            else:
                raise Exception("DALLÂ·E did not return a valid image URL.")
        else:
            raise Exception("DALLÂ·E API returned an empty response.")

    except Exception as e:
        print(f"âš  DALLÂ·E failed: {e}")
        print("ğŸ–¼ Using default background for thumbnail...")
        img = Image.open("thumbnail_bg.jpg").resize((1280, 720))

    # Ø§ÛŒØ¬Ø§Ø¯ Ù…ØªÙ† Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype("impact.ttf", 90)
    text_position = (100, 550)

    # Ø§ÙÚ©Øª Ø§Ø³ØªØ±ÙˆÚ© Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ù‡ØªØ±
    for offset in range(-3, 4, 2):
        draw.text((text_position[0] + offset, text_position[1]), topic, font=font, fill="black")
        draw.text((text_position[0], text_position[1] + offset), topic, font=font, fill="black")

    draw.text(text_position, topic, font=font, fill="yellow")

    # Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ØªØµÙˆÛŒØ± Ù†Ù‡Ø§ÛŒÛŒ
    img.save(output_file)
    print(f"âœ… Thumbnail saved as {output_file}")
    return output_file

def analyze_past_videos():

    #ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ Ù…Ø­ØªÙˆØ§

    analytics_file = "video_analytics.json"

    if not os.path.exists(analytics_file):
        print("âš  No past video analytics found.")
        return None

    with open(analytics_file, "r") as file:
        try:
            data = json.load(file)
            if not isinstance(data, dict):
                print("âš  Invalid analytics data format.")
                return None
        except json.JSONDecodeError:
            print("âš  Error reading analytics file.")
            return None

    best_videos = sorted(
        [(vid, stats) for vid, stats in data.items() if "engagement_rate" in stats],
        key=lambda x: x[1]["engagement_rate"],
        reverse=True
    )

    if not best_videos:
        print("âš  No valid engagement data found.")
        return None

    print("\nğŸ“Š **Top Performing Videos:**")
    for video_id, stats in best_videos[:5]:
        print(f"- Video ID: {video_id}, Engagement Rate: {stats['engagement_rate']:.2%}")

    return best_videos

def suggest_improvements():
    
    #Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø§Ø³ØªØ±Ø§ØªÚ˜ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚ Ù‚Ø¨Ù„ÛŒ.
    
    best_videos = analyze_past_videos()
    
    if not best_videos:
        print("âš  Not enough data to suggest improvements.")
        return

    engagement_rates = [vid[1]["engagement_rate"] for vid in best_videos]
    avg_engagement = sum(engagement_rates) / len(engagement_rates) if engagement_rates else 0

    print(f"\nğŸ“Š **Average Engagement Rate:** {avg_engagement:.2%}")

    if avg_engagement < 0.03:
        print("âš  Engagement rate is low. Consider experimenting with different topics and styles.")
    else:
        print("\nğŸ¯ **Suggested Video Strategies Based on Past Success:**")
        print("- Use more engaging hooks in the first 5 seconds.")
        print("- Focus on topics similar to high-performing videos.")
        print("- Encourage more comments by asking interactive questions.")
        print("- Test different thumbnail styles (e.g., bold text, bright colors).")
        
    script= generate_video_script(topic)

def check_copyright_violation(script):
    
    #Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªÙ† ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ú©Ù¾ÛŒâ€ŒØ±Ø§ÛŒØª.
    prompt = f"""
    Please analyze the following script for any copyright violations, plagiarism, or YouTube policy violations.
    If the script is safe, return "SAFE".
    If the script contains potential copyright or policy issues, return a short explanation.

    Script:
    {script}
    """

    try:
        response = client.chat.completions.create(
         model="gpt-3.5-turbo",  # ÛŒØ§ "o3-mini"
         messages=[{"role": "user", "content": prompt}],
         max_tokens=250
)
   
        result = response["choices"][0]["message"]["content"]

        if "SAFE" in result:
            print("âœ… Script is safe.")
            return True
        else:
            print(f"âš  Potential issue detected: {result}")
            return False
    except Exception as e:
        print("âŒ Error checking copyright:", str(e))
        return True  # Ø§Ú¯Ø± Ú†Ú©ÛŒÙ†Ú¯ Ø§Ù†Ø¬Ø§Ù… Ù†Ø´Ø¯ØŒ Ø§Ø¬Ø§Ø²Ù‡ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø± Ø±ÙˆÙ†Ø¯ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ†
if script and check_copyright_violation(script):
    with open("video_script.txt", "w") as file:
        file.write(script)
    print("ğŸ“œ Video script saved successfully!")
else:
    print("âŒ Script rejected due to potential copyright or policy violations.")

def check_youtube_policy(title, description):
    
    #Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù†ÙˆØ§Ù† Ùˆ ØªÙˆØ¶ÛŒØ­Ø§Øª Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¹Ø¯Ù… Ù†Ù‚Ø¶ Ù‚ÙˆØ§Ù†ÛŒÙ† ÛŒÙˆØªÛŒÙˆØ¨.
    
    prompt = f"""
    Please analyze the following YouTube video metadata to check if it violates YouTube's policies.
    If it's safe, return "SAFE".
    If there is a potential issue, return a short explanation.

    Title: {title}
    Description: {description}
    """

    try:
        response = client.chat.completions.create(
          model="gpt-3.5-turbo",  # ÛŒØ§ "o3-mini"
          messages=[{"role": "user", "content": prompt}],
          max_tokens=250
)

        result = response["choices"][0]["message"]["content"]

        if "SAFE" in result:
            print("âœ… Metadata is safe.")
            return True
        else:
            print(f"âš  Potential policy issue detected: {result}")
            return False
    except Exception as e:
        print("âŒ Error checking YouTube policy:", str(e))
        return True
video_metadata = generate_video_metadata(topic)
# Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯
if video_metadata and check_youtube_policy(video_metadata["title"], video_metadata["description"]):
    upload_video(enhanced_video, video_id)
else:
    print("âŒ Video upload blocked due to policy violation.")

def check_audio_copyright(audio_file):
    
    #Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ Ù…ÙˆØ³ÛŒÙ‚ÛŒ ÛŒØ§ ØµØ¯Ø§Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ú©Ù¾ÛŒâ€ŒØ±Ø§ÛŒØª Ø¯Ø§Ø±Ø¯ ÛŒØ§ Ø®ÛŒØ±.
    
    prompt = f"""
    Please analyze the following audio file and determine if it contains copyrighted music or speech.
    If it's safe, return "SAFE".
    If there is a potential copyright issue, return a short explanation.

    Audio file: {audio_file}
    """





    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=100
        )
        result = response["choices"][0]["message"]["content"]

        if "SAFE" in result:
            print("âœ… Audio is safe.")
            return True
        else:
            print(f"âš  Potential copyright issue detected: {result}")
            return False
    except Exception as e:
        print("âŒ Error checking audio copyright:", str(e))
        return True

# Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…ÙˆØ³ÛŒÙ‚ÛŒ ÛŒØ§ ØµØ¯Ø§Ú¯Ø°Ø§Ø±ÛŒ
if check_audio_copyright("voiceover.mp3"):
    enhanced_voiceover = enhance_audio("voiceover.mp3")
else:
    print("âŒ Audio rejected due to potential copyright violation.")

def check_video_content(video_file):
    
    #Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ø¨Ø±Ø§ÛŒ Ù…Ø­ØªÙˆØ§ÛŒ Ø­Ø³Ø§Ø³ ÛŒØ§ Ù…Ù…Ù†ÙˆØ¹Ù‡.
    
    prompt = f"""
    Please analyze the following video file and determine if it contains sensitive, inappropriate, or copyrighted content.
    If it's safe, return "SAFE".
    If there is a potential issue, return a short explanation.

    Video file: {video_file}
    """

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=100
        )
        result = response["choices"][0]["message"]["content"]

        if "SAFE" in result:
            print("âœ… Video content is safe.")
            return True
        else:
            print(f"âš  Potential issue detected: {result}")
            return False
    except Exception as e:
        print("âŒ Error checking video content:", str(e))
        return True

# Ø¨Ø±Ø±Ø³ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ
if check_video_content("final_video.mp4"):
    upload_video(enhanced_video, video_id)
else:
    print("âŒ Video upload blocked due to potential violation.")

# Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø§Ù…Ø±ÙˆØ² Ú†Ù†Ø¯ ÙˆÛŒØ¯ÛŒÙˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡
def check_upload_limit():
    today = datetime.now(EST).strftime('%Y-%m-%d')

    # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø¨Ø³Ø§Ø²
    if not os.path.exists(UPLOAD_LOG_FILE):
        with open(UPLOAD_LOG_FILE, "w") as file:
            json.dump({"date": today, "long_videos": 0, "shorts": 0}, file)

    # Ù…Ù‚Ø¯Ø§Ø± Ø¢Ù¾Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†
    with open(UPLOAD_LOG_FILE, "r") as file:
        data = json.load(file)

    # Ø§Ú¯Ø± ØªØ§Ø±ÛŒØ® ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡ØŒ Ù„Ø§Ú¯ Ø±Ø§ Ø±ÛŒØ³Øª Ú©Ù†
    if data["date"] != today:
        data = {"date": today, "long_videos": 0, "shorts": 0}

    return data

# Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù¾Ù„ÙˆØ¯Ù‡Ø§
def log_upload(video_type):
    data = check_upload_limit()
    data[video_type] += 1  # ØªØ¹Ø¯Ø§Ø¯ Ø¢Ù¾Ù„ÙˆØ¯Ù‡Ø§ÛŒ Ù†ÙˆØ¹ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¨Ø¯Ù‡

    with open(UPLOAD_LOG_FILE, "w") as file:
        json.dump(data, file)

# Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø¹Øª Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯
def get_upload_type():
    now = datetime.now(EST)
    hour = now.hour

    if 7 <= hour <= 9:
        return "long_videos"  # Ø²Ù…Ø§Ù† Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø¨Ù„Ù†Ø¯
    elif 11 <= hour <= 15:
        return "shorts"  # Ø²Ù…Ø§Ù† Ø¢Ù¾Ù„ÙˆØ¯ Shorts
    return None

# Ø¯Ø±ÛŒØ§ÙØª access token
def get_access_token():
    data = {
        "client_id": CLIENT_ID,
        "client_secret": CLIENT_SECRET,
        "refresh_token": REFRESH_TOKEN,
        "grant_type": "refresh_token"
    }
    response = requests.post(TOKEN_URL, data=data)
    response_json = response.json()
    if response.status_code != 200 or "access_token" not in response_json:
        raise Exception("Failed to get access token: " + str(response_json))
    return response_json.get("access_token")

# Ø¢Ù¾Ù„ÙˆØ¯ Ù…ØªØ§Ø¯ÛŒØªØ§ Ùˆ Ø¯Ø±ÛŒØ§ÙØª video_id
def upload_metadata(title, description, category_id=24, privacy_status="public"):
    access_token = get_access_token()
    headers = {
        "Authorization": f"Bearer {access_token}",
        "Content-Type": "application/json"
    }
    params = {"part": "snippet,status"}
    metadata = {
        "snippet": {
            "title": title,
            "description": description,
            "categoryId": category_id  # Ensure categoryId is int
        },
        "status": {
            "privacyStatus": privacy_status
        }
    }
    metadata_response = requests.post(METADATA_URL, headers=headers, params=params, json=metadata)
    if metadata_response.status_code != 200:
        print("Error uploading metadata:", metadata_response.json())
        return None
    return metadata_response.json().get("id")

# Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆ
def upload_video(video_file, video_id):
    access_token = get_access_token()
    headers = {
        "Authorization": f"Bearer {access_token}",
        "X-Upload-Content-Type": "video/mp4",
        "X-Upload-Content-Length": str(os.path.getsize(video_file))
    }
    init_request = requests.post(
        f"{UPLOAD_URL}?uploadType=resumable&part=snippet,status",
        headers=headers
    )
    if init_request.status_code != 200:
        print("Error initializing upload:", init_request.json())
        return
    upload_url = init_request.headers.get("Location")
    if not upload_url:
        print("Failed to retrieve upload URL")
        return
    with open(video_file, "rb") as file:
        upload_response = requests.put(upload_url, headers={
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "video/mp4"
        }, data=file)
    print("Upload response:", upload_response.json())

upload_video = upload_video(video_file, video_id)

# Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø± Ø²Ù…Ø§Ù† Ù…Ù†Ø§Ø³Ø¨
if __name__ == "__main__":
    print("ğŸš€ Starting the YouTube Auto-Upload Bot...")

    # 1ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ ÙˆÛŒØ¯ÛŒÙˆÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ùˆ Ø§Ø±Ø§Ø¦Ù‡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
    suggest_improvements()

    # 2ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ø°Ø®ÛŒØ±Ù‡â€ŒÛŒ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¯Ø± `trending_topics.json`
    fetch_all_trends()

    # 3ï¸âƒ£ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ±Ù†Ø¯ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ø¨Ù‡ØªØ±ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹
    selected_topic = select_best_trending_topic()
    if not selected_topic:
        print("âš  No suitable topic found, skipping video creation.")
        exit()  # Ø§Ú¯Ø± Ù…ÙˆØ¶ÙˆØ¹ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´ÙˆØ¯ØŒ Ø§Ø¬Ø±Ø§ Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯.

    print(f"ğŸ”¥ Creating a video on: {selected_topic}")

    # 4ï¸âƒ£ ØªÙˆÙ„ÛŒØ¯ Ù…ØªÙ† ÙˆÛŒØ¯ÛŒÙˆÛŒ Ø¬Ø°Ø§Ø¨ Ø¨Ø§ GPT
    script = generate_video_script(selected_topic)
    if not script:
        print("âŒ Script generation failed. Skipping video creation.")
        exit()

    with open("video_script.txt", "w") as file:
        file.write(script)
    print("ğŸ“œ Video script saved successfully!")

    # 5ï¸âƒ£ ØªÙˆÙ„ÛŒØ¯ ØµØ¯Ø§Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø² Ø±ÙˆÛŒ Ù…ØªÙ†
    voiceover = generate_voiceover(script)
    if not voiceover:
        print("âŒ Voiceover generation failed. Skipping video creation.")
        exit()

    # 6ï¸âƒ£ ØªÙˆÙ„ÛŒØ¯ Ø²ÛŒØ±Ù†ÙˆÛŒØ³
    subtitles = generate_subtitles(voiceover)

    # 7ï¸âƒ£ ØªÙˆÙ„ÛŒØ¯ ÙˆÛŒØ¯ÛŒÙˆ Ù†Ù‡Ø§ÛŒÛŒ
    final_video = generate_video(voiceover, "minecraft_parkour.mp4")
    if not final_video:
        print("âŒ Video generation failed.")
        exit()

    print(f"ğŸ¬ Video ready for editing: {final_video}")

    # 8ï¸âƒ£ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØµØ¯Ø§ Ùˆ ØªØµÙˆÛŒØ±
    enhanced_voiceover = enhance_audio(voiceover)  # Ø­Ø°Ù Ù†ÙˆÛŒØ² Ùˆ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
    enhanced_video = enhance_video(final_video)  # Ø§ÙØ²ÙˆØ¯Ù† Ø§ÙÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ

    # 9ï¸âƒ£ ØªÙˆÙ„ÛŒØ¯ ØªØ§Ù…Ø¨Ù†ÛŒÙ„ Ø¨Ø±Ø§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ
    thumbnail = generate_thumbnail(selected_topic)

    # ğŸ”Ÿ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÙÚ©Øªâ€ŒÙ‡Ø§ÛŒ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¨Ù‡ ÙˆÛŒØ¯ÛŒÙˆ
    final_video_with_effects = add_video_effects(enhanced_video)

    # ğŸ“ ØªÙˆÙ„ÛŒØ¯ Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ
    video_metadata = generate_video_metadata(selected_topic)
    if not video_metadata:
        video_metadata = {
            "title": f"Awesome Video About {selected_topic}!",
            "description": f"This video is all about {selected_topic}. Stay tuned for more!",
            "hashtags": "#YouTube #Trending"
        }

    title = video_metadata["title"]
    description = video_metadata["description"]
    hashtags = video_metadata["hashtags"]

    # 1ï¸âƒ£1ï¸âƒ£ Ø¢Ù¾Ù„ÙˆØ¯ Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ ÙˆÛŒØ¯ÛŒÙˆ Ùˆ Ø¯Ø±ÛŒØ§ÙØª video_id
    video_id = upload_metadata(title, description, category_id=20, privacy_status="public")
    if not video_id:
        print("âŒ Failed to upload metadata, skipping video upload.")
        exit()

    # 1ï¸âƒ£2ï¸âƒ£ Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯ÛŒÙˆÛŒ Ù†Ù‡Ø§ÛŒÛŒ
    upload_video(final_video_with_effects, video_id)

    # 1ï¸âƒ£3ï¸âƒ£ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ùˆ Ø§Ù†Ø¬Ø§Ù… Ø¢Ù† Ø¯Ø± Ø²Ù…Ø§Ù† Ù…Ù†Ø§Ø³Ø¨
    upload_type = get_upload_type()
    upload_limits = check_upload_limit()
    
    if upload_type and upload_limits[upload_type] < (MAX_LONG_UPLOADS if upload_type == "long_videos" else MAX_SHORTS_UPLOADS):
        print(f"âœ… It's time to upload a {upload_type.replace('_', ' ')}. Proceeding with upload.")

        try:
            video_file = LONG_VIDEO_FILE if upload_type == "long_videos" else SHORT_VIDEO_FILE
            category_id = 20  # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Gaming
            video_id = upload_metadata(title, description, category_id, "public")
            
            if video_id:
                upload_video(video_file, video_id)
                log_upload(upload_type)  # Ø«Ø¨Øª Ø¢Ù¾Ù„ÙˆØ¯ Ø¯Ø± Ù„Ø§Ú¯
        except Exception as e:
            print("âŒ An error occurred:", str(e))
    else:
        print("â³ Either it's not the right time for upload or today's upload limit has been reached.")
